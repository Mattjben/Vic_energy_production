---
title: "Final Project"
author: "Matthew Bentham and John Murrowood"
date: "2023-04-30"
output: 
  
    html_document:
      fig_caption: true
      
css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<center>
# Energy Demand Victoria 
##### MATH1318: Final Project \n\n
Matthew Bentham 3923076 \n
John Murrowood 3923075 \n
</center>

---

# Contents 

# 1. Introduction

**Research Question**: What are the most accurate forecasts for monthly averaged total daily electricity demand in Victoria for the next 10 months?

With the resurrection of the SEC , announcement of offshore wind farms in south east Victoria and Victoria's renewable energy target of 50% by 2030, being able to accurately predict energy demand on a continual basis is becoming more and more important. As renewable energy sources like wind and solar do not produce constant energy outputs, accurate forecasting of energy demand throughout the day is essential to ensure renewable energy sources are utilized efficiently. Although demand forecasting is increasingly relevant when incorporating renewable into the grid, demand forecasting in general reduces over and underproduction of energy and minimizes energy waste as a whole.

**Data Source:**https://www.kaggle.com/datasets/aramacus/electricity-demand-in-victoria-australia 

This data set contains the total daily energy demand across Victoria in MWh from 1st Jan 2015 to 6 Oct 2020 which consists of 2016 days. Although the additional features of this data set may not be directly relevant to this report, below is a list of variables contained in the data and their description:

- **date** : datetime, the date of the recording
- **demand** : float, a total daily electricity demand in MWh
- **RRP** : float, a recommended retail price in AUD$ / MWh
- **demand_pos_RRP** : float, a total daily demand at positive RRP in MWh
- **RRP_positive** : float, an averaged positive RRP, weighted by the corresponding intraday demand in AUD$ / MWh
- **demand_neg_RRP** : float, an total daily demand at negative RRP in MWh
- **RRP_negative** : float, an average negative RRP, weighted by the corresponding intraday demand in AUD$ / MWh
- **frac_at_neg_RRP** : float, a fraction of the day when the demand was traded at negative RRP
- **min_temperature** : float, minimum temperature during the day in Celsius
- **max_temperature** : float, maximum temperature during the day in Celsius
- **solar_exposure** : float, total daily sunlight energy in MJ/m^2
- **rainfall** : float, daily rainfall in mm
- **school_day** : boolean, if students were at school on that day
- **holiday** : boolean, if the day was a state or national holiday


*Note* : All code provided is written in Rstudio using R 4.2.0



```{r, include=FALSE}
library(readr)
library(ggplot2)
library(dplyr)
library(ggfortify)
library(xts)
library(TSA)
#remotes::install_github("cran/FitAR")
#library(FitAR)
library(tsbox)
library(lmtest)
library(tseries)
library(forecast)
```

```{r, include=FALSE}
sort.score <- function(x, score = c("bic", "aic")){
if (score == "aic"){
x[with(x, order(AIC)),]
} else if (score == "bic") {
x[with(x, order(BIC)),]
} else {
warning('score = "x" only accepts valid arguments ("aic","bic")')
}
}

Normalitytests <-  function(data,title) {
  # Create a QQ plot of the data
  
  qqnorm(y=data, main=title)
  qqline(y=data, col=2, lwd=1, lty = 2)

  # Perform a Shapiro-Wilk test on the data
  shapiro.test(as.numeric(data))
}

Plot_Model <- function(data,model_num,fignum,p,d,q,P,D,Q) {

  m.ts = Arima(data,order=c(p,d,q),seasonal=list(order=c(P,D,Q), period=12))
  res.m = residuals(m.ts);  
  par(mfrow=c(1,1))
  plot(res.m,xlab='Time',ylab='Residuals',main=paste("Figure: ", fignum, "Time series plot of model" , model_num,"residuals"))
  par(mfrow=c(1,2))
  acf(res.m,lag.max=48, main=paste("Figure: ", fignum, "ACF plot of model" , model_num,"residuals"))
  pacf(res.m,lag.max=48, main=paste("Figure: ", fignum, "PACF plot of model" , model_num,"residuals"))
  par(mfrow=c(1,1))
 return(m.ts)
}


residual.analysis <- function(model, std = TRUE,start = 2, class = c("ARIMA","GARCH","ARMA-GARCH", "fGARCH")[1]){
  library(TSA)
  
  if (class == "ARIMA"){
    if (std == TRUE){
      res.model = rstandard(model)
    }else{
      res.model = residuals(model)
    }
  }else if (class == "GARCH"){
    res.model = model$residuals[start:model$n.used]
  }else if (class == "ARMA-GARCH"){
    res.model = model@fit$residuals
  }else if (class == "fGARCH"){
    res.model = model@residuals
  }else {
    stop("The argument 'class' must be either 'ARIMA' or 'GARCH' ")
  }
  par(mfrow=c(3,2))
  plot(res.model,type='o',ylab='Standardised residuals', main="Time series plot of standardised residuals")
  abline(h=0)
  hist(res.model,main="Histogram of standardised residuals")
  qqnorm(res.model,main="QQ plot of standardised residuals")
  qqline(res.model, col = 2)
  acf(res.model,main="ACF of standardised residuals")
  print(shapiro.test(res.model))
  k=0
  LBQPlot(res.model, lag.max = 30, StartLag = k + 1, k = 0, SquaredQ = FALSE)
  par(mfrow=c(1,1))
}

Parameter.estimation <- function(data,order1,order2,method){
    model = Arima(data,order=order1,seasonal=list(order=order2, period=12),method = method)
    coeftest(model)
    residual.analysis(model = model)
    return(model)
}
    
```


# 2. Preliminary Analysis

## 2.1 Import and Analyse Dataset

To further investigate the time series data, the data set is first imported and converted to a time series object. This time series object is then plotted using the plot() function in order to visualize its main characteristics.

```{r , message=FALSE,fig.align="center",class.source="cobalt",fig.width=20, fig.height=8}

Data <- read_csv("complete_dataset.csv")

# Convert Dataframe to Timeseries:

Data_xts <- xts(Data$`demand`, Data$date)   

head(Data)
#Plot the Time Series:
plot(Data_xts,type="o",ylab="Total daily electricity demand (MWh)",xlab="Year",
     main="Figure 1:Time Series of Victoria energy demand")

```

- **Trend**: A very slight downward trend.

- **Variance**: No obvious changing variance. 

- **Seasonality**: It can be seen all the peaks occurring around July each year with short spikes occurring every January a This is as expected as generally more electricity is used during winter with the exception of very hot days during January aswell that is likely to cause large uptake in cooling systems. 

- **Change Point**: No clear change point observed


As you can see in the plot above the time series data has relatively high granularity due to the fact daily data points are used. Because of this, this data is likely to contain multiple seasonal components on the day , week and month level. As the main objective of this report is to identify and forecast trends in the electricity demand on a monthly basis, this time series data will be aggregated on monthly basis. 


```{r , message=FALSE,fig.align="center",class.source="cobalt",fig.width=20, fig.height=8}


# remove last 6 data points as they belong to separate month and will skew the summations
n<-dim(Data)[1]
df<-Data[1:(n-6),]
Data_xts <- xts(df$`demand`, df$date)  

Data_xts_agg <- apply.monthly(Data_xts,sum)

#Plot the Time Series:
plot(Data_xts_agg,type="o",ylab="Total monthly electricity demand (MWh)",xlab="Year",
     main="Figure 2:Time Series of Victoria energy demand (aggregated monthly)")
```

Time series characteristics observed from the above plot:   

- **Trend**: A very slight downward trend.    

- **Variance**: No obvious changing variance. 

- **Seasonality**: Needs to be further investigated, however annual repeating patterns can be seen around every January and july each year which strongly suggests the existence of seasonality.   

- **Change Point**: No clear change point observed



```{r , message=FALSE,fig.align="center",class.source="cobalt"}
# Summary Stats
summary(Data_xts_agg)
```

As seen in the summary data above, the data has a mean of 3654578 and a median of 3631206 , which is relatively similar indicating that the distribution is roughly symmetric if not slightly right-skewed. The min and max have a difference of 1064321 which is relatively large, indicating that there is significant variability in the data. The IQR of the data set is 423614 which indicates a moderate spread of data points around the mean. As both q1 and q3 are similar distance away from the median it can be concluded the data is relatively symmetric , however the slightly greater difference between q3 and the median does further indicate a slight positive skew. 


## 2.2 Impact of previous days

Another useful initial analysis to conduct is to determine whether or not previous years share a strong correlation or not. 
```{r}
# plot lag 1 scatterplot
plot(y=Data_xts_agg,x=zlag(Data_xts_agg),ylab="Total monthly electricity demand (MWh)", xlab='Previous months values', main = "Figure 3: Lag 1 Plot.") 
```


```{r}
y = Data_xts_agg    
x = zlag(Data_xts_agg)   # Generate first lag of the series
index = 2:length(x)  # Create an index to get rid of the first NA value in x
cor(y[index],x[index]) # Compute correlation coefficient of the data with its first lag
```


The scatter plot above shows that there is a weak positive correlation between the energy demand on a given month and its succeeding months. the correlation coefficient of 0.50 shows that the correlation is relatively weak and confirms that the time series data exhibits some form of positive autocorrelation however not a significant amount and the data is NOT randomly distributed. 

```{r}
# ACF and PACF
par(mfrow=c(1,2))
acf(Data_xts_agg,lag.max=30, main="Figure X: ACF plot of \ndaily Victorian electricity \nconsumption time series")
pacf(Data_xts_agg,lag.max=30, main="Figure X: PACF plot of \ndaily Victorian electricity \nconsumption time series")

```

From the ACF plot above we can see a very clear wave-like pattern which indicates the presence of seasonality in our data.The Pacf exhibits a slowly decreasing pattern which suggests a gradual decay of autocorrelation , suggesting the presence of a long-term/weak auto-regressive trend in the data. From this one can roughly deduce that a SARIMA model is likely going to be the best model-type for this data. 


```{r}
# ADF test to test for stationarity
adf.test(Data_xts_agg)
```
For the ADF test, a p-value less 0.05 indicates that under the 95% confidence interval the null hypothesis of non-stationarity can be rejected.The ADF test above shows a p-value of 0.088 which is greater than 0.05 , meaning the null hypothesis cannot be rejected and the time series is assumed to NOT be stationary. 

```{r}
# Check the degree of normality 
Normalitytests(Data_xts_agg,"Figure X: QQ plot of Victorian electricity consumption time series")
```
In order to test for normality in the data, Both a shaprio-wilk test and Q-Q plot was used. The shapiro-wilk test achieved a p-value of 0.06 and as this is greater than 0.05 we cannot reject the null hypothesis of normality. The Q-Q plot does show that the data follows the centre-line for the majority of points , however there still is deviation at the ends of the data meaning this data likely skirts on the edge of normality. 


# EXPLAIN THAT THERES OBIOUS SEASONALITY SO WE NEED TO ADD FREQUENCY TO THE TIME SERIES OBJECT

```{r , message=FALSE,fig.align="center",class.source="cobalt",fig.width=20, fig.height=8}

# Convert to ts object so that we can add frequency:
Data <- df                                  # Duplicate data
Data$year <- strftime(Data$date, "%Y")    # Create year column
Data$month <- strftime(Data$date, "%m")   # Create month column

Data_agg <- aggregate(`demand` ~ month + year,       # Aggregate data
                        Data,
                        FUN = sum)
# Convert data into a time series object
Data_ts_agg = matrix(Data_agg$`demand`)
Data_ts_agg = as.vector(t(Data_ts_agg))


Data_ts_agg <- ts(Data_ts_agg,frequency=12,start =c(2015,1),end =c(2020,9) )
plot(Data_ts_agg,type="o",ylab="Total monthly electricity demand (MWh)",xlab="Year",
     main="Figure 2:Time Series of Victoria energy demand (aggregated monthly)")


```



# 3. Data transformations

```{r}
# As the data is not normal a box cox transformation will be used to see if this improves normality
BC = BoxCox.ar(Data_ts_agg, lambda = seq(-2, 6, by = 0.1))
title(main = "Figure X: Optimal BoxCox transformation")

```

```{r}
lambda <- BC$lambda[which(max(BC$loglike) == BC$loglike)]
lambda
```

```{r, message=FALSE,fig.align="center",class.source="cobalt",fig.width=20, fig.height=8}
# Apply box cox transformation to time series and see if normality has improved
Data_ts_agg_BC = (Data_ts_agg^lambda-1)/lambda
#Plot the Time Series:
plot(Data_ts_agg_BC,type="o",ylab="Total monthly electricity demand (MWh)",xlab="Year",
     main="Figure X:Time Series of Victoria energy demand (aggregated monthly)")

```

As can be seen in figure X above, the BoxCox transformation does not appear to have had much effect on the time series.

```{r}
adf.test(Data_ts_agg_BC)
```

It can be seen in the ADF test above, the BoxCox transformation slightly increased the stationarity of the time series.

```{r}
# Check if normality has been improved
Normalitytests(Data_ts_agg_BC,"Figure X: QQ plot of BC Victorian electricity consumption time series")
```

As can be seen in the Shapiro Wilks test above, The boxCox transformation has resulted in the time series becoming less noraml with a p-value of 0.02. Therefore because the BC transformation has done little to improve sttionarity and nothing to improve normality, the transformation will not be used for the model.

As the model was not stationary, an initial first differencing will be applied.

```{r, message=FALSE,fig.align="center",class.source="cobalt",fig.width=20, fig.height=8}
# applying first differencing
diff.Data_ts_agg <- diff(Data_ts_agg)
par(mfrow=c(1,1))
plot(diff.Data_ts_agg,type='o',ylab = "Demand (MWh)", main='Figure X: Time series plot of differenced
     Electricity demand.')
```

Upon initial inspection, there does not appear to be any trends or changing variance. Therefore it it likely only the first differencing will be necessary.

```{r}
# Use adf test on differenced series
adf.test(diff.Data_ts_agg)
```
It can be seen on the ADF test above, the p-value of 0.01 is less than 0.05 and therefore the null hypothesis can be rejected and the differenced series can be considered stationary.

```{r}
# Test for normality of difference plot 
Normalitytests(diff.Data_ts_agg,"Figure X: QQ plot of difference time series")
```
Shapiro-Wilk test archived a p-value of greater than 0.05 , meaning under the 95% confidence interval we can assume normality.





# 4. Model specification

* TALK ABOUT WHAT MODEL WE CHOSE 

```{r}
# ACF and PACF to find period of differenced series
par(mfrow=c(1,2))
acf(diff.Data_ts_agg, main="Figure X: ACF plot of \ndifferenced daily Victorian electricity \nconsumption time series")
pacf(diff.Data_ts_agg, main="Figure X: PACF plot of \ndifferenced daily Victorian electricity \nconsumption time series")

```

# WHAT IS THE POINT OF THIS?
It can be seen in figure X above, the ACF plot appears to show a period of 6 months. This can be used for the first seasonal differencing.

### Residual Analysis

# In order to deal with the season trend effect, we will fit an intial plain model with the first seasonal difference to see if the seasonal trend is effected and to what extent. 


```{r}
# Model 1 with first seasonal differencing
m1.ts<-Plot_Model(Data_ts_agg,1,"X",0,0,0,0,1,0)
```
- Significan LAG a 1 in ACF


```{r}
# Model 2 SAMRA(0,1) with first seasonal differencing
m2.ts<-Plot_Model(Data_ts_agg,1,"X",0,0,0,0,1,1)
```
significant lag at acf 1 so trying with q =2 

```{r}
# Model 3 SAMRA(0,2) with first seasonal differencing
m3.ts<-Plot_Model(Data_ts_agg,1,"X",0,0,0,0,1,2)
```
significant lag at acf 2 so trying with q =3
```{r}
# Model 4 SAMRA(0,3) with first seasonal differencing
m4.ts<-Plot_Model(Data_ts_agg,1,"X",0,0,0,0,1,3)
```

No significant lags can conclude we have removed the seasonal trend 


```{r}
# Base model for BIC and eacf
base.ts<-Plot_Model(Data_ts_agg,1,"X",0,1,0,0,1,3)
```



Now we will look at the lags before the first significant lag. --> there is 1 significant lags in acf and 2 signifcant lag in pacf
- pacf could be a decreasing pattern 

so we will ty to use a ARIMA(2,1) model.
```{r}
# Model 5  ARIMA(2,1)+ SAMRA(0,3) with first seasonal differencing
m5.ts<-Plot_Model(Data_ts_agg,1,"X",2,1,1,0,1,3)

```
```{r}
# GET EACF
res.base = residuals(base.ts)
eacf(res.base)

```

# The tentative models are specified as 
# SARIMA(0,0,0)x(0,1,3)_12
# SARIMA(0,0,1)x(0,1,3)_12
# SARIMA(1,0,1)x(0,1,3)_12
# SARIMA(1,0,0)x(0,1,3)_12
# SARIMA(2,0,1)x(0,1,3)_12

```{r}
# BIC
par(mfrow=c(1,1))
bic_table = armasubsets(y=res.base,nar=5,nma=5,y.name='p',ar.method='ols')
plot(bic_table)

```
# The tentative models are specified as 
# SARIMA(4,0,0)x(0,1,3)_12
# SARIMA(4,0,3)x(0,1,3)_12
# SARIMA(2,0,3)x(0,1,3)_12

TOTAL SET of possible models:
# SARIMA(4,0,0)x(0,1,3)_12
# SARIMA(4,0,3)x(0,1,3)_12
# SARIMA(2,0,3)x(0,1,3)_12
# SARIMA(0,0,0)x(0,1,3)_12
# SARIMA(0,0,1)x(0,1,3)_12
# SARIMA(1,0,1)x(0,1,3)_12
# SARIMA(1,0,0)x(0,1,3)_12
# SARIMA(2,0,1)x(0,1,3)_12


# 5. Parameter Estimation
Parameter.estimation <- function(data,order1,order2,method

```{r}
# SARIMA(4,0,0)x(0,1,3)_12
m4_006 <- Parameter.estimation(Data_ts_agg,c(4,0,0),c(0,1,3),method="ML")

```
# 6. Model Diagnostics

# 7. Conclusion

# 8. References
